{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sampling in Python\n",
                "\n",
                "## Introduction to Sampling\n",
                "\n",
                "### Simple sampling with pandas\n",
                "\n",
                "Throughout this chapter, you'll be exploring song data from Spotify.\n",
                "Each row of this population dataset represents a song, and there are\n",
                "over 40,000 rows. Columns include the song name, the artists who\n",
                "performed it, the release year, and attributes of the song like its\n",
                "duration, tempo, and danceability. You'll start by looking at the\n",
                "durations.\n",
                "\n",
                "Your first task is to sample the Spotify dataset and compare the mean\n",
                "duration of the population with the sample.\n",
                "\n",
                "`spotify_population` is available and `pandas` is loaded as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Sample 1000 rows from `spotify_population`, assigning to\n",
                "  `spotify_sample`.\n",
                "- Calculate the mean duration in minutes from `spotify_population` using `pandas`.\n",
                "- Calculate the mean duration in minutes from `spotify_sample` using `pandas`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.12/site-packages (2.2.2)\n",
                        "Collecting pyarrow\n",
                        "  Downloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (3.0 kB)\n",
                        "Requirement already satisfied: numpy>=1.26.0 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
                        "Downloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_aarch64.whl (38.1 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: pyarrow\n",
                        "Successfully installed pyarrow-16.1.0\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install pandas pyarrow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(41656, 20)"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# added/edited\n",
                "import pandas as pd\n",
                "spotify_population = pd.read_feather(\"spotify_2000_2020.feather\")\n",
                "spotify_population.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "       acousticness               artists  danceability  duration_ms  \\\n",
                        "20429      0.001660              ['DNCE']         0.655     236453.0   \n",
                        "43         0.071200               ['D12']         0.800     330333.0   \n",
                        "9548       0.025600           ['The Cab']         0.569     204520.0   \n",
                        "38500      0.090400       ['Alan Menken']         0.239     140413.0   \n",
                        "27940      0.000035        ['Nickelback']         0.550     233840.0   \n",
                        "...             ...                   ...           ...          ...   \n",
                        "28321      0.009200   ['My Darkest Days']         0.663     193573.0   \n",
                        "38482      0.070800       ['Brabo Gator']         0.835     187709.0   \n",
                        "5654       0.001770  ['American Authors']         0.554     220693.0   \n",
                        "33053      0.381000            ['Doobie']         0.911     151714.0   \n",
                        "11026      0.679000     ['Donnie Elbert']         0.575     178520.0   \n",
                        "\n",
                        "       duration_minutes  energy  explicit                      id  \\\n",
                        "20429          3.940883   0.693       0.0  2igbKtoBMXdYgYPkCpl0V4   \n",
                        "43             5.505550   0.749       1.0  03NIra3KSLDgnqgIiQJNow   \n",
                        "9548           3.408667   0.944       0.0  3MpR460YBQfy8WJLQZghuD   \n",
                        "38500          2.340217   0.614       0.0  0jkGkwy510cvhy0jYPFme4   \n",
                        "27940          3.897333   0.914       0.0  56h3v9zaotemQ0NB21dlkg   \n",
                        "...                 ...     ...       ...                     ...   \n",
                        "28321          3.226217   0.914       0.0  4akbPW1whJ6VDvXYeTA3vX   \n",
                        "38482          3.128483   0.757       1.0  00rsJA8H0HO6NxWsT6ISCg   \n",
                        "5654           3.678217   0.806       0.0  4gHD93RNqEhEh2NkYzl3x6   \n",
                        "33053          2.528567   0.479       1.0  4U1j4Di9S3dSqckssFU8kl   \n",
                        "11026          2.975333   0.528       0.0  01FwouklQ4Kv0xj15t7tQU   \n",
                        "\n",
                        "       instrumentalness   key  liveness  loudness  mode  \\\n",
                        "20429          0.000000   5.0    0.0398    -5.148   0.0   \n",
                        "43             0.000000   8.0    0.0929    -6.717   0.0   \n",
                        "9548           0.000000   4.0    0.2430    -3.940   1.0   \n",
                        "38500          0.403000   4.0    0.1290    -9.819   1.0   \n",
                        "27940          0.322000   8.0    0.0894    -2.831   1.0   \n",
                        "...                 ...   ...       ...       ...   ...   \n",
                        "28321          0.000000  11.0    0.6490    -4.280   0.0   \n",
                        "38482          0.000000   8.0    0.1840    -4.851   1.0   \n",
                        "5654           0.000000   0.0    0.1650    -3.463   1.0   \n",
                        "33053          0.000005   1.0    0.1510    -5.275   0.0   \n",
                        "11026          0.000270   4.0    0.1960    -8.281   0.0   \n",
                        "\n",
                        "                                       name  popularity release_date  \\\n",
                        "20429                            Body Moves        59.0   2016-11-18   \n",
                        "43                              Shit On You        38.0   2000-01-01   \n",
                        "9548                                  La La        44.0         2011   \n",
                        "38500  Kingdom Dance - From \"Tangled\"/Score        53.0   2010-01-01   \n",
                        "27940                                S.E.X.        56.0   2008-10-28   \n",
                        "...                                     ...         ...          ...   \n",
                        "28321                            Casual Sex        55.0   2012-01-01   \n",
                        "38482                             Love Song        48.0   2010-10-02   \n",
                        "5654                                   Luck        52.0   2014-01-01   \n",
                        "33053                            Nikki Sixx        62.0   2017-12-08   \n",
                        "11026                         Have I Sinned        42.0         2005   \n",
                        "\n",
                        "       speechiness    tempo  valence    year  \n",
                        "20429       0.0372  102.028    0.868  2016.0  \n",
                        "43          0.3940  109.925    0.740  2000.0  \n",
                        "9548        0.0727  110.037    0.544  2011.0  \n",
                        "38500       0.0773  155.658    0.470  2010.0  \n",
                        "27940       0.0425  134.958    0.825  2008.0  \n",
                        "...            ...      ...      ...     ...  \n",
                        "28321       0.0453  116.034    0.874  2012.0  \n",
                        "38482       0.1570   88.009    0.819  2010.0  \n",
                        "5654        0.0460  144.923    0.646  2014.0  \n",
                        "33053       0.2020  140.006    0.682  2017.0  \n",
                        "11026       0.0398   70.195    0.528  2005.0  \n",
                        "\n",
                        "[1000 rows x 20 columns]\n",
                        "3.8521519140900073\n",
                        "3.835851583333333\n"
                    ]
                }
            ],
            "source": [
                "# Sample 1000 rows from spotify_population\n",
                "spotify_sample = spotify_population.sample(n=1000)\n",
                "\n",
                "# Print the sample\n",
                "print(spotify_sample)\n",
                "\n",
                "# Calculate the mean duration in mins from spotify_population\n",
                "mean_dur_pop = spotify_population[\"duration_minutes\"].mean()\n",
                "\n",
                "# Calculate the mean duration in mins from spotify_sample\n",
                "mean_dur_samp = spotify_sample[\"duration_minutes\"].mean()\n",
                "\n",
                "# Print the means\n",
                "print(mean_dur_pop)\n",
                "print(mean_dur_samp)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Simple sampling and calculating with NumPy\n",
                "\n",
                "You can also use `numpy` to calculate parameters or statistics from a\n",
                "list or `pandas` Series.\n",
                "\n",
                "You'll be turning it up to eleven and looking at the `loudness` property\n",
                "of each song.\n",
                "\n",
                "`spotify_population` is available and `numpy` is loaded as `np`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create a `pandas` Series, `loudness_pop`, by subsetting the `loudness`\n",
                "  column from `spotify_population`.\n",
                "- Sample `loudness_pop` to get 100 random values, assigning to\n",
                "  `loudness_samp`.\n",
                "- Calculate the mean of `loudness_pop` using `numpy`.\n",
                "- Calculate the mean of `loudness_samp` using `numpy`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "20891   -3.186\n",
                        "22326   -5.603\n",
                        "26957   -6.807\n",
                        "27953   -7.816\n",
                        "12454   -2.855\n",
                        "         ...  \n",
                        "35364   -4.510\n",
                        "40356   -6.189\n",
                        "36540   -6.121\n",
                        "35766   -1.795\n",
                        "39134   -7.538\n",
                        "Name: loudness, Length: 100, dtype: float64\n",
                        "-7.366856851353947\n",
                        "-7.3899799999999995\n"
                    ]
                }
            ],
            "source": [
                "# Create a pandas Series from the loudness column of spotify_population\n",
                "loudness_pop = spotify_population['loudness']\n",
                "\n",
                "# Sample 100 values of loudness_pop\n",
                "loudness_samp = loudness_pop.sample(n=100)\n",
                "\n",
                "print(loudness_samp)\n",
                "\n",
                "\n",
                "# Calculate the mean of loudness_pop\n",
                "mean_loudness_pop = np.mean(loudness_pop)\n",
                "\n",
                "# Calculate the mean of loudness_samp\n",
                "mean_loudness_samp = np.mean(loudness_samp)\n",
                "\n",
                "print(mean_loudness_pop)\n",
                "print(mean_loudness_samp)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Are findings from the sample generalizable?\n",
                "\n",
                "You just saw how convenience sampling—collecting data using the easiest\n",
                "method—can result in samples that aren't representative of the\n",
                "population. Equivalently, this means findings from the sample are not\n",
                "generalizable to the population. Visualizing the distributions of the\n",
                "population and the sample can help determine whether or not the sample\n",
                "is representative of the population.\n",
                "\n",
                "The Spotify dataset contains an `acousticness` column, which is a\n",
                "confidence measure from zero to one of whether the track was made with\n",
                "instruments that aren't plugged in. You'll compare the `acousticness`\n",
                "distribution of the total population of songs with a sample of those\n",
                "songs.\n",
                "\n",
                "`spotify_population` and `spotify_mysterious_sample` are available;\n",
                "`pandas` as `pd`, `matplotlib.pyplot` as `plt`, and `numpy` as `np` are\n",
                "loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Plot a histogram of the `acousticness` from `spotify_population` with\n",
                "  bins of width `0.01` from `0` to `1` using pandas `.hist()`.\n",
                "- Update the histogram code to use the `spotify_mysterious_sample` dataset.\n",
                "\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Collecting matplotlib\n",
                        "  Downloading matplotlib-3.9.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (11 kB)\n",
                        "Collecting contourpy>=1.0.1 (from matplotlib)\n",
                        "  Downloading contourpy-1.2.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.8 kB)\n",
                        "Collecting cycler>=0.10 (from matplotlib)\n",
                        "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
                        "Collecting fonttools>=4.22.0 (from matplotlib)\n",
                        "  Downloading fonttools-4.53.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (162 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
                        "  Downloading kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.4 kB)\n",
                        "Requirement already satisfied: numpy>=1.23 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
                        "Collecting pillow>=8 (from matplotlib)\n",
                        "  Downloading pillow-10.3.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (9.2 kB)\n",
                        "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
                        "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /home/vscode/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
                        "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
                        "Downloading matplotlib-3.9.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (8.2 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
                        "\u001b[?25hDownloading contourpy-1.2.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (285 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
                        "Downloading fonttools-4.53.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (4.8 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hDownloading kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.5 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hDownloading pillow-10.3.0-cp312-cp312-manylinux_2_28_aarch64.whl (4.3 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
                        "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.0 kiwisolver-1.4.5 matplotlib-3.9.0 pillow-10.3.0 pyparsing-3.1.2\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Visualize the distribution of acousticness with a histogram\n",
                "spotify_population['acousticness'].hist(bins=np.arange(0, 1.01, 0.01))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Update the histogram to use spotify_mysterious_sample\n",
                "spotify_mysterious_sample['acousticness'].hist(bins=np.arange(0, 1.01, 0.01))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Are these findings generalizable?\n",
                "\n",
                "Let's look at another sample to see if it is representative of the\n",
                "population. This time, you'll look at the `duration_minutes` column of\n",
                "the Spotify dataset, which contains the length of the song in minutes.\n",
                "\n",
                "`spotify_population` and `spotify_mysterious_sample2` are available;\n",
                "`pandas`, `matplotlib.pyplot`, and `numpy` are loaded using their\n",
                "standard aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Plot a histogram of `duration_minutes` from `spotify_population` with\n",
                "  bins of width `0.5` from `0` to `15` using pandas `.hist()`.\n",
                "- Update the histogram code to use the `spotify_mysterious_sample2` dataset.\n",
                "\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the distribution of duration_minutes as a histogram\n",
                "spotify_population['duration_minutes'].hist(bins=np.arange(0, 15.5, 0.5))\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# Update the histogram to use spotify_mysterious_sample2\n",
                "spotify_mysterious_sample2['duration_minutes'].hist(bins=np.arange(0, 15.5, 0.5))\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generating random numbers\n",
                "\n",
                "You've used `.sample()` to generate pseudo-random numbers from a set of\n",
                "values in a DataFrame. A related task is to generate random numbers that\n",
                "follow a statistical distribution, like the uniform distribution or the\n",
                "normal distribution.\n",
                "\n",
                "Each random number generation function has distribution-specific\n",
                "arguments and an argument for specifying the number of random numbers to\n",
                "generate.\n",
                "\n",
                "`matplotlib.pyplot` is loaded as `plt`, and `numpy` is loaded as `np`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Generate 5000 numbers from a uniform distribution, setting the\n",
                "  parameters `low` to `-3` and `high` to `3`.\n",
                "- Generate 5000 numbers from a normal distribution, setting the parameters `loc` to `5` and `scale` to `2`.\n",
                "- Plot a histogram of `uniforms` with bins of width of `0.25` from `-3` to `3` using `plt.hist()`.\n",
                "- Plot a histogram of normals with bins of width of 0.5 from -2 to 13 using plt.hist().\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate random numbers from a Uniform(-3, 3)\n",
                "uniforms = np.random.uniform(low=-3, high=3, size=5000)\n",
                "\n",
                "# Print uniforms\n",
                "print(uniforms)\n",
                "\n",
                "\n",
                "# Generate random numbers from a Uniform(-3, 3)\n",
                "uniforms = np.random.uniform(low=-3, high=3, size=5000)\n",
                "\n",
                "# Generate random numbers from a Normal(5, 2)\n",
                "normals = np.random.normal(loc=5, scale=2, size=5000)\n",
                "\n",
                "# Print normals\n",
                "print(normals)\n",
                "\n",
                "\n",
                "# Generate random numbers from a Uniform(-3, 3)\n",
                "uniforms = np.random.uniform(low=-3, high=3, size=5000)\n",
                "\n",
                "# Plot a histogram of uniform values, binwidth 0.25\n",
                "plt.hist(uniforms, bins=np.arange(-3, 3.25, 0.25))\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# Generate random numbers from a Normal(5, 2)\n",
                "normals = np.random.normal(loc=5, scale=2, size=5000)\n",
                "\n",
                "# Plot a histogram of normal values, binwidth 0.5\n",
                "plt.hist(normals, bins=np.arange(-2, 13.5, 0.5))\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sampling Methods\n",
                "\n",
                "### Simple random sampling\n",
                "\n",
                "The simplest method of sampling a population is the one you've seen\n",
                "already. It is known as *simple random sampling* (sometimes abbreviated\n",
                "to \"SRS\"), and involves picking rows at random, one at a time, where\n",
                "each row has the same chance of being picked as any other.\n",
                "\n",
                "In this chapter, you'll apply sampling methods to a synthetic\n",
                "(fictional) employee attrition dataset from IBM, where \"attrition\" in\n",
                "this context means leaving the company.\n",
                "\n",
                "`attrition_pop` is available; `pandas` as `pd` is loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Sample 70 rows from `attrition_pop` using simple random sampling,\n",
                "  setting the random seed to `18900217`.\n",
                "- Print the sample dataset, `attrition_samp`. *What do you notice about\n",
                "  the indices?*\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample 70 rows using simple random sampling and set the seed\n",
                "attrition_samp = attrition_pop.sample(n=70, random_state=18900217)\n",
                "\n",
                "# Print the sample\n",
                "print(attrition_samp)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Systematic sampling\n",
                "\n",
                "One sampling method that avoids randomness is called *systematic\n",
                "sampling*. Here, you pick rows from the population at regular intervals.\n",
                "\n",
                "For example, if the population dataset had one thousand rows, and you\n",
                "wanted a sample size of five, you could pick rows `0`, `200`, `400`,\n",
                "`600`, and `800`.\n",
                "\n",
                "`attrition_pop` is available; `pandas` has been pre-loaded as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Set the sample size to `70`.\n",
                "- Calculate the population size from `attrition_pop`.\n",
                "- Calculate the interval between the rows to be sampled.\n",
                "- Systematically sample `attrition_pop` to get the rows of the population at each `interval`, starting at 0; assign the rows to `attrition_sys_samp`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the sample size to 70\n",
                "sample_size = 70\n",
                "\n",
                "# Calculate the population size from attrition_pop\n",
                "pop_size = len(attrition_pop)\n",
                "\n",
                "# Calculate the interval\n",
                "interval = pop_size // sample_size\n",
                "\n",
                "\n",
                "# Set the sample size to 70\n",
                "sample_size = 70\n",
                "\n",
                "# Calculate the population size from attrition_pop\n",
                "pop_size = len(attrition_pop)\n",
                "\n",
                "# Calculate the interval\n",
                "interval = pop_size // sample_size\n",
                "\n",
                "# Systematically sample 70 rows\n",
                "attrition_sys_samp = attrition_pop.iloc[::interval]\n",
                "\n",
                "# Print the sample\n",
                "print(attrition_sys_samp)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Is systematic sampling OK?\n",
                "\n",
                "Systematic sampling has a problem: if the data has been sorted, or there\n",
                "is some sort of pattern or meaning behind the row order, then the\n",
                "resulting sample may not be representative of the whole population. The\n",
                "problem can be solved by shuffling the rows, but then systematic\n",
                "sampling is equivalent to simple random sampling.\n",
                "\n",
                "Here you'll look at how to determine whether or not there is a problem.\n",
                "\n",
                "`attrition_pop` is available; `pandas` is loaded as `pd`, and\n",
                "`matplotlib.pyplot` as `plt`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Add an index column to `attrition_pop`, assigning the result to\n",
                "  `attrition_pop_id`.\n",
                "- Create a scatter plot of `YearsAtCompany` versus `index` for\n",
                "  `attrition_pop_id` using pandas `.plot()`.\n",
                "- Randomly shuffle the rows of `attrition_pop`.\n",
                "- Reset the row indexes, and add an index column to `attrition_pop`.\n",
                "- Repeat the scatter plot of `YearsAtCompany` versus `index`, this time using `attrition_shuffled`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add an index column to attrition_pop\n",
                "attrition_pop_id = attrition_pop.reset_index()\n",
                "\n",
                "# Plot YearsAtCompany vs. index for attrition_pop_id\n",
                "attrition_pop_id.plot(x=\"index\", y=\"YearsAtCompany\", kind=\"scatter\")\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# Shuffle the rows of attrition_pop\n",
                "attrition_shuffled = attrition_pop.sample(frac=1)\n",
                "\n",
                "# Reset the row indexes and create an index column\n",
                "attrition_shuffled = attrition_shuffled.reset_index(drop=True).reset_index()\n",
                "\n",
                "# Plot YearsAtCompany vs. index for attrition_shuffled\n",
                "attrition_shuffled.plot(x=\"index\", y=\"YearsAtCompany\", kind=\"scatter\")\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Proportional stratified sampling\n",
                "\n",
                "If you are interested in subgroups within the population, then you may\n",
                "need to carefully control the counts of each subgroup within the\n",
                "population. *Proportional stratified sampling* results in subgroup sizes\n",
                "within the sample that are representative of the subgroup sizes within\n",
                "the population. It is equivalent to performing a simple random sample on\n",
                "each subgroup.\n",
                "\n",
                "`attrition_pop` is available; `pandas` is loaded with its usual alias.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Get the proportion of employees by `Education` level from\n",
                "  `attrition_pop`.\n",
                "- Use proportional stratified sampling on `attrition_pop` to sample 40% of each `Education` group, setting the seed to `2022`.\n",
                "- Get the proportion of employees by `Education` level from `attrition_strat`.\n",
                "\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Proportion of employees by Education level\n",
                "education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)\n",
                "\n",
                "# Print education_counts_pop\n",
                "print(education_counts_pop)\n",
                "\n",
                "\n",
                "# Proportion of employees by Education level\n",
                "education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)\n",
                "\n",
                "# Print education_counts_pop\n",
                "print(education_counts_pop)\n",
                "\n",
                "# Proportional stratified sampling for 40% of each Education group\n",
                "attrition_strat = attrition_pop.groupby('Education')\\\n",
                "\t.sample(frac=0.4, random_state=2022)\n",
                "\n",
                "# Print the sample\n",
                "print(attrition_strat)\n",
                "\n",
                "\n",
                "# Proportion of employees by Education level\n",
                "education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)\n",
                "\n",
                "# Print education_counts_pop\n",
                "print(education_counts_pop)\n",
                "\n",
                "# Proportional stratified sampling for 40% of each Education group\n",
                "attrition_strat = attrition_pop.groupby('Education')\\\n",
                "\t.sample(frac=0.4, random_state=2022)\n",
                "\n",
                "# Calculate the Education level proportions from attrition_strat\n",
                "education_counts_strat = attrition_strat['Education'].value_counts(normalize=True)\n",
                "\n",
                "# Print education_counts_strat\n",
                "print(education_counts_strat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Equal counts stratified sampling\n",
                "\n",
                "If one subgroup is larger than another subgroup in the population, but\n",
                "you don't want to reflect that difference in your analysis, then you can\n",
                "use *equal counts stratified sampling* to generate samples where each\n",
                "subgroup has the same amount of data. For example, if you are analyzing\n",
                "blood types, O is the most common blood type worldwide, but you may wish\n",
                "to have equal amounts of O, A, B, and AB in your sample.\n",
                "\n",
                "`attrition_pop` is available; `pandas` is loaded with its usual alias.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Use equal counts stratified sampling on `attrition_pop` to get 30\n",
                "  employees from each `Education` group, setting the seed to `2022`.\n",
                "- Get the proportion of employees by `Education` level from `attrition_eq`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get 30 employees from each Education group\n",
                "attrition_eq = attrition_pop.groupby('Education')\\\n",
                "\t.sample(n=30, random_state=2022)      \n",
                "         \n",
                "# Print the sample\n",
                "print(attrition_eq)\n",
                "\n",
                "\n",
                "# Get 30 employees from each Education group\n",
                "attrition_eq = attrition_pop.groupby('Education')\\\n",
                "\t.sample(n=30, random_state=2022)      \n",
                "\n",
                "# Get the proportions from attrition_eq\n",
                "education_counts_eq = attrition_eq['Education'].value_counts(normalize=True) \n",
                "\n",
                "# Print the results\n",
                "print(education_counts_eq)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Weighted sampling\n",
                "\n",
                "Stratified sampling provides rules about the probability of picking rows\n",
                "from your dataset at the subgroup level. A generalization of this is\n",
                "*weighted sampling*, which lets you specify rules about the probability\n",
                "of picking rows at the row level. The probability of picking any given\n",
                "row is proportional to the weight value for that row.\n",
                "\n",
                "`attrition_pop` is available; `pandas`, `matplotlib.pyplot`, and `numpy`\n",
                "are loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Plot `YearsAtCompany` from `attrition_pop` as a histogram with bins of\n",
                "  width `1` from `0` to `40`.\n",
                "- Sample 400 employees from `attrition_pop` weighted by `YearsAtCompany`.\n",
                "- Plot `YearsAtCompany` from `attrition_weight` as a histogram with bins of width `1` from `0` to `40`.\n",
                "\n",
                "\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot YearsAtCompany from attrition_pop as a histogram\n",
                "attrition_pop['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# Plot YearsAtCompany from attrition_pop as a histogram\n",
                "attrition_pop['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
                "plt.show()\n",
                "\n",
                "# Sample 400 employees weighted by YearsAtCompany\n",
                "attrition_weight = attrition_pop.sample(n=400, weights=\"YearsAtCompany\")\n",
                "\n",
                "# Print the sample\n",
                "print(attrition_weight)\n",
                "\n",
                "\n",
                "# Plot YearsAtCompany from attrition_pop as a histogram\n",
                "attrition_pop['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
                "plt.show()\n",
                "\n",
                "# Sample 400 employees weighted by YearsAtCompany\n",
                "attrition_weight = attrition_pop.sample(n=400, weights=\"YearsAtCompany\")\n",
                "\n",
                "# Plot YearsAtCompany from attrition_weight as a histogram\n",
                "attrition_weight['YearsAtCompany'].hist(bins=np.arange(0, 41, 1))\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performing cluster sampling\n",
                "\n",
                "Now that you know when to use cluster sampling, it's time to put it into\n",
                "action. In this exercise, you'll explore the `JobRole` column of the\n",
                "attrition dataset. You can think of each job role as a subgroup of the\n",
                "whole population of employees.\n",
                "\n",
                "`attrition_pop` is available; `pandas` is loaded with its usual alias,\n",
                "and the `random` package is available. A seed of `19790801` has also\n",
                "been set with `random.seed()`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Create a list of unique `JobRole` values from `attrition_pop`, and\n",
                "  assign to `job_roles_pop`.\n",
                "- Randomly sample four `JobRole` values from `job_roles_pop`.\n",
                "- Subset `attrition_pop` for the sampled job roles by filtering for rows where `JobRole` is in `job_roles_samp`.\n",
                "- Remove any unused categories from `JobRole`.\n",
                "- For each job role in the filtered dataset, take a random sample of ten rows, setting the seed to `2022`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a list of unique JobRole values\n",
                "job_roles_pop = list(attrition_pop['JobRole'].unique())\n",
                "\n",
                "# Randomly sample four JobRole values\n",
                "job_roles_samp = random.sample(job_roles_pop, k=4)\n",
                "\n",
                "# Print the result\n",
                "print(job_roles_samp)\n",
                "\n",
                "\n",
                "# Create a list of unique JobRole values\n",
                "job_roles_pop = list(attrition_pop['JobRole'].unique())\n",
                "\n",
                "# Randomly sample four JobRole values\n",
                "job_roles_samp = random.sample(job_roles_pop, k=4)\n",
                "\n",
                "# Filter for rows where JobRole is in job_roles_samp\n",
                "jobrole_condition = attrition_pop['JobRole'].isin(job_roles_samp)\n",
                "attrition_filtered = attrition_pop[jobrole_condition]\n",
                "\n",
                "# Print the result\n",
                "print(attrition_filtered)\n",
                "\n",
                "\n",
                "# Create a list of unique JobRole values\n",
                "job_roles_pop = list(attrition_pop['JobRole'].unique())\n",
                "\n",
                "# Randomly sample four JobRole values\n",
                "job_roles_samp = random.sample(job_roles_pop, k=4)\n",
                "\n",
                "# Filter for rows where JobRole is in job_roles_samp\n",
                "jobrole_condition = attrition_pop['JobRole'].isin(job_roles_samp)\n",
                "attrition_filtered = attrition_pop[jobrole_condition]\n",
                "\n",
                "# Remove categories with no rows\n",
                "attrition_filtered['JobRole'] = attrition_filtered['JobRole'].cat.remove_unused_categories()\n",
                "\n",
                "# Randomly sample 10 employees from each sampled job role\n",
                "attrition_clust = attrition_filtered.groupby(\"JobRole\")\\\n",
                "    .sample(n=10, random_state=2022)\n",
                "\n",
                "# Print the sample\n",
                "print(attrition_clust)         \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3 kinds of sampling\n",
                "\n",
                "You're going to compare the performance of point estimates using simple,\n",
                "stratified, and cluster sampling. Before doing that, you'll have to set\n",
                "up the samples.\n",
                "\n",
                "You'll use the `RelationshipSatisfaction` column of the `attrition_pop`\n",
                "dataset, which categorizes the employee's relationship with the company.\n",
                "It has four levels: `Low`, `Medium`, `High`, and `Very_High`. `pandas`\n",
                "has been loaded with its usual alias, and the `random` package has been\n",
                "loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Perform simple random sampling on `attrition_pop` to get one-quarter\n",
                "  of the population, setting the seed to `2022`.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Perform stratified sampling on `attrition_pop` to sample one-quarter\n",
                "  of each `RelationshipSatisfaction` group, setting the seed to `2022`.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Create a list of unique values from `attrition_pop`'s\n",
                "  `RelationshipSatisfaction` column.\n",
                "- Randomly sample `satisfaction_unique` to get two values.\n",
                "- Subset the population for rows where `RelationshipSatisfaction` is in\n",
                "  `satisfaction_samp` and clear any unused categories from\n",
                "  `RelationshipSatisfaction`; assign to `attrition_clust_prep`.\n",
                "- Perform cluster sampling on the selected satisfaction groups, sampling\n",
                "  one quarter of the *population* and setting the seed to `2022`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform simple random sampling to get 0.25 of the population\n",
                "attrition_srs = attrition_pop.sample(frac=0.25, random_state=2022)\n",
                "\n",
                "\n",
                "# Perform stratified sampling to get 0.25 of each relationship group\n",
                "attrition_strat = attrition_pop.groupby(\"RelationshipSatisfaction\")\\\n",
                "    .sample(frac=0.25, random_state=2022)\n",
                "\n",
                "\n",
                "# Create a list of unique RelationshipSatisfaction values\n",
                "satisfaction_unique = list(attrition_pop['RelationshipSatisfaction'].unique())\n",
                "\n",
                "# Randomly sample 2 unique satisfaction values\n",
                "satisfaction_samp = random.sample(satisfaction_unique, k=2)\n",
                "\n",
                "# Filter for satisfaction_samp and clear unused categories from RelationshipSatisfaction\n",
                "satis_condition = attrition_pop['RelationshipSatisfaction'].isin(satisfaction_samp)\n",
                "attrition_clust_prep = attrition_pop[satis_condition]\n",
                "attrition_clust_prep['RelationshipSatisfaction'] = attrition_clust_prep['RelationshipSatisfaction'].cat.remove_unused_categories()\n",
                "\n",
                "# Perform cluster sampling on the selected group, getting 0.25 of attrition_pop\n",
                "attrition_clust = attrition_clust_prep.groupby(\"RelationshipSatisfaction\")\\\n",
                "    .sample(n=len(attrition_pop) // 4, random_state=2022)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Comparing point estimates\n",
                "\n",
                "Now that you have three types of sample (simple, stratified, and\n",
                "cluster), you can compare point estimates from each sample to the\n",
                "population parameter. That is, you can calculate the same summary\n",
                "statistic on each sample and see how it compares to the summary\n",
                "statistic for the population.\n",
                "\n",
                "Here, we'll look at how satisfaction with the company affects whether or\n",
                "not the employee leaves the company. That is, you'll calculate the\n",
                "proportion of employees who left the company (they have an `Attrition`\n",
                "value of `1`) for each value of `RelationshipSatisfaction`.\n",
                "\n",
                "`attrition_pop`, `attrition_srs`, `attrition_strat`, and\n",
                "`attrition_clust` are available; `pandas` is loaded with its usual\n",
                "alias.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "Group `attrition_pop` by `RelationshipSatisfaction` levels and calculate\n",
                "the mean of `Attrition` for each level.\n",
                "\n",
                "Calculate the proportion of employee attrition for each relationship\n",
                "satisfaction group, this time on the simple random sample,\n",
                "`attrition_srs`.\n",
                "\n",
                "Calculate the proportion of employee attrition for each relationship\n",
                "satisfaction group, this time on the stratified sample,\n",
                "`attrition_strat`.\n",
                "\n",
                "Calculate the proportion of employee attrition for each relationship\n",
                "satisfaction group, this time on the cluster sample, `attrition_clust`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mean Attrition by RelationshipSatisfaction group\n",
                "mean_attrition_pop = attrition_pop.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
                "\n",
                "# Print the result\n",
                "print(mean_attrition_pop)\n",
                "\n",
                "\n",
                "# Calculate the same thing for the simple random sample \n",
                "mean_attrition_srs = attrition_srs.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
                "\n",
                "# Print the result\n",
                "print(mean_attrition_srs)\n",
                "\n",
                "\n",
                "# Calculate the same thing for the stratified sample \n",
                "mean_attrition_strat = attrition_strat.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
                "\n",
                "# Print the result\n",
                "print(mean_attrition_strat)\n",
                "\n",
                "\n",
                "# Calculate the same thing for the cluster sample \n",
                "mean_attrition_clust = attrition_clust.groupby('RelationshipSatisfaction')['Attrition'].mean()\n",
                "\n",
                "# Print the result\n",
                "print(mean_attrition_clust)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sampling Distributions\n",
                "\n",
                "### Calculating relative errors\n",
                "\n",
                "The size of the sample you take affects how accurately the point\n",
                "estimates reflect the corresponding population parameter. For example,\n",
                "when you calculate a sample mean, you want it to be close to the\n",
                "population mean. However, if your sample is too small, this might not be\n",
                "the case.\n",
                "\n",
                "The most common metric for assessing accuracy is *relative error*. This\n",
                "is the absolute difference between the population parameter and the\n",
                "point estimate, all divided by the population parameter. It is sometimes\n",
                "expressed as a percentage.\n",
                "\n",
                "`attrition_pop` and `mean_attrition_pop` (the mean of the `Attrition`\n",
                "column of `attrition_pop`) are available; `pandas` is loaded as `pd`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Generate a simple random sample from `attrition_pop` of fifty rows,\n",
                "  setting the seed to `2022`.\n",
                "- Calculate the mean employee `Attrition` in the sample.\n",
                "- Calculate the relative error between `mean_attrition_srs50` and\n",
                "  `mean_attrition_pop` as a *percentage*.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Calculate the *relative error percentage* again. This time, use a\n",
                "  simple random sample of one hundred rows of `attrition_pop`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a simple random sample of 50 rows, with seed 2022\n",
                "attrition_srs50 = attrition_pop.sample(n=50, random_state=2022)\n",
                "\n",
                "# Calculate the mean employee attrition in the sample\n",
                "mean_attrition_srs50 = attrition_srs50['Attrition'].mean()\n",
                "\n",
                "# Calculate the relative error percentage\n",
                "rel_error_pct50 = 100 * abs(mean_attrition_pop - mean_attrition_srs50) / mean_attrition_pop\n",
                "\n",
                "# Print rel_error_pct50\n",
                "print(rel_error_pct50)\n",
                "\n",
                "\n",
                "# Generate a simple random sample of 100 rows, with seed 2022\n",
                "attrition_srs100 = attrition_pop.sample(n=100, random_state=2022)\n",
                "\n",
                "# Calculate the mean employee attrition in the sample\n",
                "mean_attrition_srs100 = attrition_srs100['Attrition'].mean()\n",
                "\n",
                "# Calculate the relative error percentage\n",
                "rel_error_pct100 = 100 * abs(mean_attrition_pop - mean_attrition_srs100) / mean_attrition_pop\n",
                "\n",
                "# Print rel_error_pct100\n",
                "print(rel_error_pct100)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Replicating samples\n",
                "\n",
                "When you calculate a point estimate such as a sample mean, the value you\n",
                "calculate depends on the rows that were included in the sample. That\n",
                "means that there is some randomness in the answer. In order to quantify\n",
                "the variation caused by this randomness, you can create many samples and\n",
                "calculate the sample mean (or another statistic) for each sample.\n",
                "\n",
                "`attrition_pop` is available; `pandas` and `matplotlib.pyplot` are\n",
                "loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Replicate the provided code so that it runs `500` times. Assign the\n",
                "  resulting list of sample means to `mean_attritions`.\n",
                "- Draw a histogram of the `mean_attritions` list with 16 bins.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create an empty list\n",
                "mean_attritions = []\n",
                "# Loop 500 times to create 500 sample means\n",
                "for i in range(500):\n",
                "\tmean_attritions.append(\n",
                "    \tattrition_pop.sample(n=60)['Attrition'].mean()\n",
                "\t)\n",
                "  \n",
                "# Print out the first few entries of the list\n",
                "print(mean_attritions[0:5])\n",
                "\n",
                "\n",
                "# Create an empty list\n",
                "mean_attritions = []\n",
                "# Loop 500 times to create 500 sample means\n",
                "for i in range(500):\n",
                "\tmean_attritions.append(\n",
                "    \tattrition_pop.sample(n=60)['Attrition'].mean()\n",
                "\t)\n",
                "\n",
                "# Create a histogram of the 500 sample means\n",
                "plt.hist(mean_attritions, bins=16)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exact sampling distribution\n",
                "\n",
                "To quantify how the point estimate (sample statistic) you are interested\n",
                "in varies, you need to know all the possible values it can take and how\n",
                "often. That is, you need to know its distribution.\n",
                "\n",
                "The distribution of a sample statistic is called the *sampling\n",
                "distribution*. When we can calculate this exactly, rather than using an\n",
                "approximation, it is known as the *exact sampling distribution*.\n",
                "\n",
                "Let's take another look at the sampling distribution of dice rolls. This\n",
                "time, we'll look at five eight-sided dice. (These have the numbers one\n",
                "to eight.)\n",
                "\n",
                "![8 sided\n",
                "die](https://assets.datacamp.com/production/repositories/5975/datasets/001ee1102f4838b0806d9b3592ce76ce454c3892/shutterstock_231673213_8_sided_die.jpeg)\n",
                "\n",
                "`pandas`, `numpy`, and `matplotlib.pyplot` are loaded with their usual\n",
                "aliases. The `expand_grid()` function is also available, which expects a\n",
                "dictionary of key-value pairs as its argument. The definition of the\n",
                "`expand_grid()` function is provided in the [pandas\n",
                "documentation](https://pandas.pydata.org/pandas-docs/version/0.17.1/cookbook.html#creating-example-data).\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Expand a grid representing 5 8-sided dice. That is, create a DataFrame\n",
                "  with five columns from a dictionary, named `die1` to `die5`. The rows\n",
                "  should contain all possibilities for throwing five dice, each numbered\n",
                "  `1` to `8`.\n",
                "- Add a column, `mean_roll`, to `dice`, that contains the mean of the five rolls as a categorical.\n",
                "- Create a bar plot of the `mean_roll` categorical column, so it displays the count of each `mean_roll` in increasing order from `1.0` to `8.0`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Expand a grid representing 5 8-sided dice\n",
                "dice = expand_grid(\n",
                "  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die2': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die3': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die4': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die5': [1, 2, 3, 4, 5, 6, 7, 8]\n",
                "  })\n",
                "\n",
                "# Print the result\n",
                "print(dice)\n",
                "\n",
                "\n",
                "# Expand a grid representing 5 8-sided dice\n",
                "dice = expand_grid(\n",
                "  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die2': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die3': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die4': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die5': [1, 2, 3, 4, 5, 6, 7, 8]\n",
                "  })\n",
                "\n",
                "# Add a column of mean rolls and convert to a categorical\n",
                "dice['mean_roll'] = (dice['die1'] + dice['die2'] + \n",
                "                     dice['die3'] + dice['die4'] + \n",
                "                     dice['die5']) / 5\n",
                "dice['mean_roll'] = dice['mean_roll'].astype('category')\n",
                "\n",
                "# Print result\n",
                "print(dice)\n",
                "\n",
                "\n",
                "# Expand a grid representing 5 8-sided dice\n",
                "dice = expand_grid(\n",
                "  {'die1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die2': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die3': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die4': [1, 2, 3, 4, 5, 6, 7, 8],\n",
                "   'die5': [1, 2, 3, 4, 5, 6, 7, 8]\n",
                "  })\n",
                "\n",
                "# Add a column of mean rolls and convert to a categorical\n",
                "dice['mean_roll'] = (dice['die1'] + dice['die2'] + \n",
                "                     dice['die3'] + dice['die4'] + \n",
                "                     dice['die5']) / 5\n",
                "dice['mean_roll'] = dice['mean_roll'].astype('category')\n",
                "\n",
                "# Draw a bar plot of mean_roll\n",
                "dice['mean_roll'].value_counts(sort=False).plot(kind=\"bar\")\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generating an approximate sampling distribution\n",
                "\n",
                "Calculating the exact sampling distribution is only possible in very\n",
                "simple situations. With just five eight-sided dice, the number of\n",
                "possible rolls is `8**5`, which is over thirty thousand. When the\n",
                "dataset is more complicated, for example, where a variable has hundreds\n",
                "or thousands of categories, the number of possible outcomes becomes too\n",
                "difficult to compute exactly.\n",
                "\n",
                "In this situation, you can calculate an *approximate sampling\n",
                "distribution* by simulating the exact sampling distribution. That is,\n",
                "you can repeat a procedure over and over again to simulate both the\n",
                "sampling process and the sample statistic calculation process.\n",
                "\n",
                "`pandas`, `numpy`, and `matplotlib.pyplot` are loaded with their usual\n",
                "aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Sample one to eight, five times, with replacement. Assign to\n",
                "  `five_rolls`.\n",
                "- Calculate the mean of `five_rolls`.\n",
                "- Replicate the sampling code 1000 times, assigning each result to the list `sample_means_1000`.\n",
                "- Plot `sample_means_1000` as a histogram with `20` bins.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample one to eight, five times, with replacement\n",
                "five_rolls = np.random.choice(list(range(1, 9)), size=5, replace=True)\n",
                "\n",
                "# Print the mean of five_rolls\n",
                "print(five_rolls.mean())\n",
                "\n",
                "\n",
                "# Replicate the sampling code 1000 times\n",
                "sample_means_1000 = []\n",
                "for i in range(1000):\n",
                "    sample_means_1000.append(\n",
                "  \t\tnp.random.choice(list(range(1, 9)), size=5, replace=True).mean()\n",
                "    )\n",
                "\n",
                "# Print the first 10 entries of the result\n",
                "print(sample_means_1000[0:10])\n",
                "\n",
                "\n",
                "# Replicate the sampling code 1000 times\n",
                "sample_means_1000 = []\n",
                "for i in range(1000):\n",
                "    sample_means_1000.append(\n",
                "  \t\tnp.random.choice(list(range(1, 9)), size=5, replace=True).mean()\n",
                "    )\n",
                "\n",
                "# Draw a histogram of sample_means_1000 with 20 bins\n",
                "plt.hist(sample_means_1000, bins=20)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Population & sampling distribution means\n",
                "\n",
                "One of the useful features of sampling distributions is that you can\n",
                "quantify them. Specifically, you can calculate summary statistics on\n",
                "them. Here, you'll look at the relationship between the mean of the\n",
                "sampling distribution and the population parameter's mean.\n",
                "\n",
                "Three sampling distributions are provided. For each, the employee\n",
                "attrition dataset was sampled using simple random sampling, then the\n",
                "mean attrition was calculated. This was done 1000 times to get a\n",
                "sampling distribution of mean attritions. One sampling distribution used\n",
                "a sample size of 5 for each replicate, one used 50, and one used 500.\n",
                "\n",
                "`attrition_pop`, `sampling_distribution_5`, `sampling_distribution_50`,\n",
                "and `sampling_distribution_500` are available; `numpy` as `np` is\n",
                "loaded.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the mean of `sampling_distribution_5`,\n",
                "  `sampling_distribution_50`, and `sampling_distribution_500` (a mean of\n",
                "  sample means).\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the mean of the mean attritions for each sampling distribution\n",
                "mean_of_means_5 = np.mean(sampling_distribution_5)\n",
                "mean_of_means_50 = np.mean(sampling_distribution_50)\n",
                "mean_of_means_500 = np.mean(sampling_distribution_500)\n",
                "\n",
                "# Print the results\n",
                "print(mean_of_means_5)\n",
                "print(mean_of_means_50)\n",
                "print(mean_of_means_500)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Population & sampling distribution variation\n",
                "\n",
                "You just calculated the mean of the sampling distribution and saw how it\n",
                "is an estimate of the corresponding population parameter. Similarly, as\n",
                "a result of the central limit theorem, the standard deviation of the\n",
                "sampling distribution has an interesting relationship with the\n",
                "population parameter's standard deviation and the sample size.\n",
                "\n",
                "`attrition_pop`, `sampling_distribution_5`, `sampling_distribution_50`,\n",
                "and `sampling_distribution_500` are available; `numpy` is loaded with\n",
                "its usual alias.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Calculate the standard deviation of `sampling_distribution_5`,\n",
                "  `sampling_distribution_50`, and `sampling_distribution_500` (a\n",
                "  standard deviation of sample means).\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the std. dev. of the mean attritions for each sampling distribution\n",
                "sd_of_means_5 = np.std(sampling_distribution_5, ddof=1)\n",
                "sd_of_means_50 = np.std(sampling_distribution_50, ddof=1)\n",
                "sd_of_means_500 = np.std(sampling_distribution_500, ddof=1)\n",
                "\n",
                "# Print the results\n",
                "print(sd_of_means_5)\n",
                "print(sd_of_means_50)\n",
                "print(sd_of_means_500)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bootstrap Distributions\n",
                "\n",
                "### Generating a bootstrap distribution\n",
                "\n",
                "The process for generating a bootstrap distribution is similar to the\n",
                "process for generating a sampling distribution; only the first step is\n",
                "different.\n",
                "\n",
                "To make a sampling distribution, you start with the population and\n",
                "sample without replacement. To make a bootstrap distribution, you start\n",
                "with a sample and sample that with replacement. After that, the steps\n",
                "are the same: calculate the summary statistic that you are interested in\n",
                "on that sample/resample, then replicate the process many times. In each\n",
                "case, you can visualize the distribution with a histogram.\n",
                "\n",
                "Here, `spotify_sample` is a subset of the `spotify_population` dataset.\n",
                "To make it easier to see how resampling works, a row index column called\n",
                "`'index'` has been added, and only the artist name, song name, and\n",
                "`danceability` columns have been included.\n",
                "\n",
                "`spotify_sample` is available; `pandas`, `numpy`, and\n",
                "`matplotlib.pyplot` are loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Generate a single bootstrap resample from `spotify_sample`.\n",
                "- Calculate the mean of the `danceability` column of `spotify_1_resample` using numpy.\n",
                "- Replicate the expression provided 1000 times.\n",
                "- Create a bootstrap distribution by drawing a histogram of `mean_danceability_1000`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate 1 bootstrap resample\n",
                "spotify_1_resample = spotify_sample.sample(frac=1, replace=True)\n",
                "\n",
                "# Print the resample\n",
                "print(spotify_1_resample)\n",
                "\n",
                "\n",
                "# Generate 1 bootstrap resample\n",
                "spotify_1_resample = spotify_sample.sample(frac=1, replace=True)\n",
                "\n",
                "# Calculate of the danceability column of spotify_1_resample\n",
                "mean_danceability_1 = np.mean(spotify_1_resample['danceability'])\n",
                "\n",
                "# Print the result\n",
                "print(mean_danceability_1)\n",
                "\n",
                "\n",
                "# Replicate this 1000 times\n",
                "mean_danceability_1000 = []\n",
                "for i in range(1000):\n",
                "\tmean_danceability_1000.append(\n",
                "        np.mean(spotify_sample.sample(frac=1, replace=True)['danceability'])\n",
                "\t)\n",
                "  \n",
                "# Print the result\n",
                "print(mean_danceability_1000)\n",
                "\n",
                "\n",
                "# Replicate this 1000 times\n",
                "mean_danceability_1000 = []\n",
                "for i in range(1000):\n",
                "\tmean_danceability_1000.append(\n",
                "        np.mean(spotify_sample.sample(frac=1, replace=True)['danceability'])\n",
                "\t)\n",
                "\n",
                "# Draw a histogram of the resample means\n",
                "plt.hist(mean_danceability_1000)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sampling distribution vs. bootstrap distribution\n",
                "\n",
                "The sampling distribution and bootstrap distribution are closely linked.\n",
                "In situations where you can repeatedly sample from a population (these\n",
                "occasions are rare), it's helpful to generate both the sampling\n",
                "distribution and the bootstrap distribution, one after the other, to see\n",
                "how they are related.\n",
                "\n",
                "Here, the statistic you are interested in is the mean `popularity` score\n",
                "of the songs.\n",
                "\n",
                "`spotify_population` (the whole dataset) and `spotify_sample` (`500`\n",
                "randomly sampled rows from `spotify_population`) are available; `pandas`\n",
                "and `numpy` are loaded with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Generate a sampling distribution of 2000 replicates.\n",
                "- Sample 500 rows of the population without replacement and calculate\n",
                "  the mean `popularity`.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Generate a bootstrap distribution of 2000 replicates.\n",
                "- Sample 500 rows of the sample with replacement and calculate the mean\n",
                "  `popularity`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mean_popularity_2000_samp = []\n",
                "\n",
                "# Generate a sampling distribution of 2000 replicates\n",
                "for i in range(2000):\n",
                "    mean_popularity_2000_samp.append(\n",
                "    \t# Sample 500 rows and calculate the mean popularity     \n",
                "    \tspotify_population.sample(n=500)['popularity'].mean()\n",
                "    )\n",
                "\n",
                "# Print the sampling distribution results\n",
                "print(mean_popularity_2000_samp)\n",
                "\n",
                "\n",
                "mean_popularity_2000_boot = []\n",
                "\n",
                "# Generate a bootstrap distribution of 2000 replicates\n",
                "for i in range(2000):\n",
                "    mean_popularity_2000_boot.append(\n",
                "    \t# Resample 500 rows and calculate the mean popularity\n",
                "    \tspotify_sample.sample(n=500, replace=True)['popularity'].mean()\n",
                "    )\n",
                "\n",
                "# Print the bootstrap distribution results\n",
                "print(mean_popularity_2000_boot)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Compare sampling and bootstrap means\n",
                "\n",
                "To make calculation easier, distributions similar to those calculated\n",
                "from the previous exercise have been included, this time using a sample\n",
                "size of `5000`.\n",
                "\n",
                "`spotify_population`, `spotify_sample`, `sampling_distribution`, and\n",
                "`bootstrap_distribution` are available; `pandas` and `numpy` are loaded\n",
                "with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "Calculate the mean `popularity` in 4 ways:\n",
                "\n",
                "- Population: from `spotify_population`, take the mean of `popularity`.\n",
                "- Sample: from `spotify_sample`, take the mean of `popularity`.\n",
                "- Sampling distribution: from `sampling_distribution`, take its mean.\n",
                "- Bootstrap distribution: from `bootstrap_distribution`, take its mean.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the population mean popularity\n",
                "pop_mean = spotify_population['popularity'].mean()\n",
                "\n",
                "# Calculate the original sample mean popularity\n",
                "samp_mean = spotify_sample['popularity'].mean()\n",
                "\n",
                "# Calculate the sampling dist'n estimate of mean popularity\n",
                "samp_distn_mean = np.mean(sampling_distribution)\n",
                "\n",
                "# Calculate the bootstrap dist'n estimate of mean popularity\n",
                "boot_distn_mean = np.mean(bootstrap_distribution)\n",
                "\n",
                "# Print the means\n",
                "print([pop_mean, samp_mean, samp_distn_mean, boot_distn_mean])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Compare sampling and bootstrap standard deviations\n",
                "\n",
                "In the same way that you looked at how the sampling distribution and\n",
                "bootstrap distribution could be used to estimate the population mean,\n",
                "you'll now take a look at how they can be used to estimate variation, or\n",
                "more specifically, the standard deviation, in the population.\n",
                "\n",
                "Recall that the sample size is `5000`.\n",
                "\n",
                "`spotify_population`, `spotify_sample`, `sampling_distribution`, and\n",
                "`bootstrap_distribution` are available; `pandas` and `numpy` are loaded\n",
                "with their usual aliases.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "Calculate the standard deviation of `popularity` in 4 ways.\n",
                "\n",
                "- Population: from `spotify_population`, take the standard deviation of\n",
                "  `popularity`.\n",
                "- Original sample: from `spotify_sample`, take the standard deviation of\n",
                "  `popularity`.\n",
                "- Sampling distribution: from `sampling_distribution`, take its standard\n",
                "  deviation and multiply by the square root of the sample size (`5000`).\n",
                "- Bootstrap distribution: from `bootstrap_distribution`, take its\n",
                "  standard deviation and multiply by the square root of the sample size.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the population std dev popularity\n",
                "pop_sd = spotify_population['popularity'].std(ddof=0)\n",
                "\n",
                "# Calculate the original sample std dev popularity\n",
                "samp_sd = spotify_sample['popularity'].std()\n",
                "\n",
                "# Calculate the sampling dist'n estimate of std dev popularity\n",
                "samp_distn_sd = np.std(sampling_distribution, ddof=1) * np.sqrt(5000)\n",
                "\n",
                "# Calculate the bootstrap dist'n estimate of std dev popularity\n",
                "boot_distn_sd = np.std(bootstrap_distribution, ddof=1) * np.sqrt(5000)\n",
                "\n",
                "# Print the standard deviations\n",
                "print([pop_sd, samp_sd, samp_distn_sd, boot_distn_sd])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Calculating confidence intervals\n",
                "\n",
                "You have learned about two methods for calculating confidence intervals:\n",
                "the *quantile method* and the *standard error method*. The standard\n",
                "error method involves using the inverse cumulative distribution function\n",
                "(inverse CDF) of the normal distribution to calculate confidence\n",
                "intervals. In this exercise, you'll perform these two methods on the\n",
                "Spotify data.\n",
                "\n",
                "`spotify_population`, `spotify_sample`, and `bootstrap_distribution` are\n",
                "available; `pandas` and `numpy` are loaded with their usual aliases, and\n",
                "`norm` has been loaded from `scipy.stats`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Generate a 95% confidence interval using the quantile method on the\n",
                "  bootstrap distribution, setting the `0.025` quantile as `lower_quant`\n",
                "  and the `0.975` quantile as `upper_quant`.\n",
                "\n",
                "Generate a 95% confidence interval using the standard error method from\n",
                "the bootstrap distribution.\n",
                "\n",
                "- Calculate `point_estimate` as the mean of `bootstrap_distribution`,\n",
                "  and `standard_error` as the standard deviation of\n",
                "  `bootstrap_distribution`.\n",
                "- Calculate `lower_se` as the `0.025` quantile of an inv. CDF from a\n",
                "  normal distribution with mean `point_estimate` and standard deviation\n",
                "  `standard_error`.\n",
                "- Calculate `upper_se` as the `0.975` quantile of that same inv. CDF.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a 95% confidence interval using the quantile method\n",
                "lower_quant = np.quantile(bootstrap_distribution, 0.025)\n",
                "upper_quant = np.quantile(bootstrap_distribution, 0.975)\n",
                "\n",
                "# Print quantile method confidence interval\n",
                "print((lower_quant, upper_quant))\n",
                "\n",
                "\n",
                "# Find the mean and std dev of the bootstrap distribution\n",
                "point_estimate = np.mean(bootstrap_distribution)\n",
                "standard_error = np.std(bootstrap_distribution, ddof=1)\n",
                "\n",
                "# Find the lower limit of the confidence interval\n",
                "lower_se = norm.ppf(0.025, loc=point_estimate, scale=standard_error)\n",
                "\n",
                "# Find the upper limit of the confidence interval\n",
                "upper_se = norm.ppf(0.975, loc=point_estimate, scale=standard_error)\n",
                "\n",
                "# Print standard error method confidence interval\n",
                "print((lower_se, upper_se))\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
